{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был выбран датасет классификации эмоций человека. Задача может иметь множество приложений в реальной жизни. Например, подобная система может использоваться для анализа и предсказания поведения людей\n",
    "\n",
    "https://www.kaggle.com/datasets/sayakbera/fer-2013-7-emotions-uniform-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (78.1.0)\n",
      "Requirement already satisfied: six>=1.10 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Requirement already satisfied: pandas in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sayakbera/fer-2013-7-emotions-uniform-dataset\n",
      "License(s): unknown\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d sayakbera/fer-2013-7-emotions-uniform-dataset -p data --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/204.1 MB 1.6 MB/s eta 0:02:06\n",
      "   ---------------------------------------- 1.3/204.1 MB 3.2 MB/s eta 0:01:04\n",
      "    --------------------------------------- 2.6/204.1 MB 4.8 MB/s eta 0:00:43\n",
      "    --------------------------------------- 2.6/204.1 MB 4.8 MB/s eta 0:00:43\n",
      "    --------------------------------------- 5.0/204.1 MB 4.8 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 5.8/204.1 MB 4.6 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 7.9/204.1 MB 5.4 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 9.7/204.1 MB 5.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.3/204.1 MB 6.0 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 13.1/204.1 MB 6.4 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 14.7/204.1 MB 6.5 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 16.5/204.1 MB 6.7 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 18.9/204.1 MB 7.0 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 20.4/204.1 MB 7.0 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 22.5/204.1 MB 7.2 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 24.6/204.1 MB 7.4 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 26.5/204.1 MB 7.5 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 28.6/204.1 MB 7.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 30.9/204.1 MB 7.8 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 32.5/204.1 MB 7.8 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 34.6/204.1 MB 7.9 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 37.0/204.1 MB 8.0 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 38.8/204.1 MB 8.0 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 40.9/204.1 MB 8.1 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 43.3/204.1 MB 8.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 45.1/204.1 MB 8.2 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 47.2/204.1 MB 8.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 49.8/204.1 MB 8.4 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 51.6/204.1 MB 8.4 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 53.7/204.1 MB 8.5 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 54.5/204.1 MB 8.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 57.1/204.1 MB 8.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 58.7/204.1 MB 8.4 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 60.3/204.1 MB 8.4 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 61.9/204.1 MB 8.4 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 63.2/204.1 MB 8.4 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 65.0/204.1 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 66.8/204.1 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 68.2/204.1 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 70.0/204.1 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 71.3/204.1 MB 8.2 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 73.1/204.1 MB 8.3 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 74.7/204.1 MB 8.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 76.3/204.1 MB 8.2 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 78.4/204.1 MB 8.3 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 80.0/204.1 MB 8.2 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 81.5/204.1 MB 8.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 83.6/204.1 MB 8.3 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 85.2/204.1 MB 8.2 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 87.0/204.1 MB 8.3 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 88.9/204.1 MB 8.3 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 90.4/204.1 MB 8.3 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 92.3/204.1 MB 8.3 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 94.1/204.1 MB 8.3 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 95.7/204.1 MB 8.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 97.8/204.1 MB 8.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 99.1/204.1 MB 8.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 101.2/204.1 MB 8.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 102.8/204.1 MB 8.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 103.0/204.1 MB 8.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 105.9/204.1 MB 8.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 107.0/204.1 MB 8.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 108.3/204.1 MB 8.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 109.8/204.1 MB 8.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 111.1/204.1 MB 8.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 112.2/204.1 MB 8.1 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 113.8/204.1 MB 8.1 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 115.3/204.1 MB 8.1 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 116.4/204.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 118.0/204.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 119.5/204.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 120.8/204.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 122.4/204.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 124.0/204.1 MB 7.9 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 125.3/204.1 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 126.9/204.1 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 128.7/204.1 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 129.8/204.1 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 131.3/204.1 MB 7.9 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 133.2/204.1 MB 7.9 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 134.5/204.1 MB 7.9 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 136.1/204.1 MB 7.9 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 137.9/204.1 MB 7.9 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 139.2/204.1 MB 7.8 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 140.2/204.1 MB 7.8 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 141.8/204.1 MB 7.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 143.7/204.1 MB 7.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 145.0/204.1 MB 7.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 146.5/204.1 MB 7.8 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 148.4/204.1 MB 7.8 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 149.7/204.1 MB 7.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 151.3/204.1 MB 7.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 152.8/204.1 MB 7.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 154.1/204.1 MB 7.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 155.7/204.1 MB 7.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 157.3/204.1 MB 7.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 158.9/204.1 MB 7.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 160.2/204.1 MB 7.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 161.5/204.1 MB 7.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 163.3/204.1 MB 7.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.6/204.1 MB 7.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 166.2/204.1 MB 7.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 168.0/204.1 MB 7.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 169.3/204.1 MB 7.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 170.9/204.1 MB 7.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 172.8/204.1 MB 7.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 174.1/204.1 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 175.6/204.1 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 177.5/204.1 MB 7.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 178.8/204.1 MB 7.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 180.4/204.1 MB 7.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 182.2/204.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 183.5/204.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 185.3/204.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 186.9/204.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 188.5/204.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 190.1/204.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 191.4/204.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 193.2/204.1 MB 7.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.8/204.1 MB 7.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.3/204.1 MB 7.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 198.4/204.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.8/204.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.1/204.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/204.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 204.1/204.1 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.2 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.2 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 111.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.0 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0 typing-extensions-4.13.1\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: torch==2.6.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torchvision) (2.6.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-11.1.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.21.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading pillow-11.1.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.6 MB 104.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.8/2.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-11.1.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим статистику по классам в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "классы - ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']\n",
      "картинок в train: 56000\n",
      "картинок в val: 7000\n",
      "картинок в test: 7000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=transform)\n",
    "val_data = datasets.ImageFolder(root=\"data/FER2013_7emotions_Uniform_Augmented_Dataset/validation\", transform=transform)\n",
    "test_data = datasets.ImageFolder(root=\"data/FER2013_7emotions_Uniform_Augmented_Dataset/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"классы -\", train_data.classes)\n",
    "print(\"картинок в train:\", len(train_data))\n",
    "print(\"картинок в val:\", len(val_data))\n",
    "print(\"картинок в test:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp313-cp313-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 1.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.6/8.1 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.6/8.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.6/8.1 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.2/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.3/8.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp313-cp313-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 79.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на несколько изображений из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img.numpy().squeeze()\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 4))\n",
    "for i in range(5):\n",
    "    img, label = train_data[i]\n",
    "    axes[i].imshow(img.numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[i].set_title(train_data.classes[label])\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества будем использовать accuracy - как показатель верно угаданных классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: filelock in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp313-cp313-win_amd64.whl (2728.9 MB)\n",
      "   ---------------------------------------- 0.0/2.7 GB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 GB 37.7 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 0.0/2.7 GB 51.3 MB/s eta 0:00:53\n",
      "   ---------------------------------------- 0.0/2.7 GB 47.3 MB/s eta 0:00:58\n",
      "    --------------------------------------- 0.0/2.7 GB 58.0 MB/s eta 0:00:47\n",
      "    --------------------------------------- 0.1/2.7 GB 61.4 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.4 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.0 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.8 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.5 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.2 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 0.1/2.7 GB 63.5 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.2/2.7 GB 63.8 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.2/2.7 GB 64.0 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 0.2/2.7 GB 64.2 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 0.2/2.7 GB 64.3 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 0.2/2.7 GB 64.5 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.2/2.7 GB 63.9 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 0.2/2.7 GB 64.7 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.3/2.7 GB 64.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.3/2.7 GB 67.3 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 67.1 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 66.0 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 66.0 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 66.2 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 0.3/2.7 GB 66.6 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 65.1 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 66.4 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 65.5 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 65.5 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 0.4/2.7 GB 65.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 0.4/2.7 GB 65.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 0.4/2.7 GB 65.5 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 0.5/2.7 GB 65.9 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 0.5/2.7 GB 65.6 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 65.6 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 65.1 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 64.3 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 63.9 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 63.4 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 63.4 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 62.9 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 62.4 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 62.1 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 63.4 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 0.6/2.7 GB 64.4 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.6/2.7 GB 64.3 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.6/2.7 GB 64.6 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.6/2.7 GB 64.3 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.7/2.7 GB 60.8 MB/s eta 0:00:35\n",
      "   --------- ------------------------------ 0.7/2.7 GB 59.6 MB/s eta 0:00:35\n",
      "   --------- ------------------------------ 0.7/2.7 GB 59.9 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 61.0 MB/s eta 0:00:34\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 60.7 MB/s eta 0:00:34\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 60.7 MB/s eta 0:00:34\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 60.8 MB/s eta 0:00:33\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 61.7 MB/s eta 0:00:33\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 62.0 MB/s eta 0:00:32\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 62.7 MB/s eta 0:00:32\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 63.2 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 63.5 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 0.8/2.7 GB 63.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.8/2.7 GB 63.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.9/2.7 GB 63.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.9/2.7 GB 63.1 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.9/2.7 GB 62.0 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 0.9/2.7 GB 63.0 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 0.9/2.7 GB 62.5 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 0.9/2.7 GB 65.3 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 0.9/2.7 GB 66.6 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 0.9/2.7 GB 65.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.0 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 1.0/2.7 GB 65.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.0/2.7 GB 65.8 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.1/2.7 GB 65.4 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.1/2.7 GB 65.4 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.1/2.7 GB 64.5 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 64.9 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 64.9 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 65.0 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 65.9 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 1.2/2.7 GB 66.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 67.1 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.8 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.3 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 1.2/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 1.3/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 1.3/2.7 GB 66.5 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 1.3/2.7 GB 66.1 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 1.3/2.7 GB 65.4 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.3/2.7 GB 66.4 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.3/2.7 GB 64.6 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.3/2.7 GB 62.5 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 1.3/2.7 GB 63.8 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.4/2.7 GB 63.2 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 1.4/2.7 GB 63.6 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 1.5/2.7 GB 63.2 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 1.5/2.7 GB 63.1 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 1.5/2.7 GB 63.1 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 1.5/2.7 GB 62.8 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 61.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 61.4 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 63.4 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 62.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 1.6/2.7 GB 62.5 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 65.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 66.8 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 65.6 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 65.2 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 64.3 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 1.6/2.7 GB 64.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.6 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.5 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.7/2.7 GB 64.5 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.7/2.7 GB 64.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.7/2.7 GB 64.0 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.8/2.7 GB 65.8 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 1.8/2.7 GB 66.2 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 66.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.3 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.1 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.5 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 1.9/2.7 GB 65.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 1.9/2.7 GB 65.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 1.9/2.7 GB 66.5 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 1.9/2.7 GB 65.1 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 1.9/2.7 GB 65.2 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 1.9/2.7 GB 67.1 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 1.9/2.7 GB 66.7 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 2.0/2.7 GB 66.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 2.0/2.7 GB 67.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 2.0/2.7 GB 67.1 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.4 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.5 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 64.0 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.8 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 63.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 63.4 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 63.4 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 61.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 61.1 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 61.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 2.1/2.7 GB 60.6 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 2.1/2.7 GB 61.4 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 2.2/2.7 GB 61.2 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 2.2/2.7 GB 61.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 2.2/2.7 GB 61.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 61.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 61.1 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 60.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 60.2 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 2.3/2.7 GB 64.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 2.3/2.7 GB 64.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 2.3/2.7 GB 63.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 2.3/2.7 GB 63.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 2.3/2.7 GB 63.6 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 2.3/2.7 GB 69.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.3/2.7 GB 65.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 GB 65.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 GB 65.5 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 GB 65.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 67.4 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 64.5 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 63.1 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 63.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 62.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 2.5/2.7 GB 62.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 2.5/2.7 GB 62.1 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 2.5/2.7 GB 62.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 2.5/2.7 GB 63.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 2.5/2.7 GB 63.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 2.5/2.7 GB 64.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 2.5/2.7 GB 63.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 2.5/2.7 GB 63.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 2.6/2.7 GB 63.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 2.6/2.7 GB 63.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 GB 64.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.7/2.7 GB 63.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.7/2.7 GB 66.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 64.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 GB 38.9 MB/s eta 0:00:00\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp313-cp313-win_amd64.whl (5.3 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-2.6.0+cu118 torchvision-0.21.0+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем использовать cuda для torch. Инициализируем transform:\n",
    "- с переводом в greyscale;\n",
    "- ресайз до 224 на 224 (на чем была обучена бейзлайн модель);\n",
    "- в формат tensor;\n",
    "- с нормализацией.\n",
    "\n",
    "Инициализируем даталоадеры для train выборки и validation выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18, vit_b_16\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#import random\n",
    "#from torch.utils.data import Subset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_data = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=transform)\n",
    "train_data_vit = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=vit_transform)\n",
    "\n",
    "#subset = random.sample(range(len(train_data)), int(0.2 * len(train_data)))\n",
    "#train_subset = Subset(train_data, subset) ###\n",
    "# batchsize будет 32\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "train_loader_vit = DataLoader(train_data_vit, batch_size=32, shuffle=True)\n",
    "#val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(train_data.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве сверточной модели будем использовать resnet18. скачаем ее и сделаем свою функцию для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# загружаем модель resnet, меняем ей входной слой\n",
    "model_cnn = resnet18(pretrained=True)\n",
    "model_cnn.fc = nn.Linear(model_cnn.fc.in_features, num_classes)\n",
    "\n",
    "#отправляем на gpu\n",
    "model_cnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.01) #lr пока поставим 0.01\n",
    "\n",
    "#фнукция для обучения моделей с промежуточным выводом\n",
    "def train_model(model, train_loader, val_loader, optimizer, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct = 0, 0\n",
    "\n",
    "        total = len(train_loader)\n",
    "        i = 0\n",
    "        for images, labels in train_loader:\n",
    "            if i % 250 == 0:\n",
    "                print(i,\"/\", total)\n",
    "            i+=1\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        print(f\"epoch {epoch+1}: loss: {total_loss/len(train_loader):.4f}, accuracy- {total_correct/len(train_data):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.9463, accuracy- 0.1890\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.7097, accuracy- 0.3270\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 1.2993, accuracy- 0.5103\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 4: loss: 1.1050, accuracy- 0.5815\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 5: loss: 0.9655, accuracy- 0.6378\n"
     ]
    }
   ],
   "source": [
    "train_model(model_cnn, train_loader, None, optimizer=optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем неплохой итоговый accuracy = 0.6378, loss 0.965 после 5 эпох с lr=0.01. Видна положительная динамика и можно сделать вывод, что при большем числе эпох accuracy будет еще выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузим трансформерную модель - будем использовать ViT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_vit = vit_b_16(pretrained=True)\n",
    "model_vit.heads.head = nn.Linear(model_vit.heads.head.in_features, num_classes)\n",
    "\n",
    "\n",
    "model_vit.to(device)\n",
    "\n",
    "# используем SGD\n",
    "optimizer_vit = optim.SGD(model_vit.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение на 3 эпохах (т.к. обучение занимает слишком продолжительное время на моей машине)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.7775, accuracy- 0.3120\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.6087, accuracy- 0.4076\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 1.5410, accuracy- 0.4349\n"
     ]
    }
   ],
   "source": [
    "train_model(model_vit, train_loader_vit, None, optimizer=optimizer_vit, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем accuracy = 0.4349, можно сделать вывод, что при большем числе эпох можно получить результат, близкий к 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотезы\n",
    "Добавим `RandomHorizontalFlip` (случайное отображение по горизонтали), `RandomRotation` (случайный поворот), `RandomCrop` (случайное обрезание), чтобы обучать на более разнообразных изображениях - это должно улучшить accuracy.\n",
    "\n",
    "Так же поменяем learning rate, добавим scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# добавляем случайности\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=train_transform)\n",
    "# val_data = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/validation\", transform=val_transform)\n",
    "train_data_vit = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=vit_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "train_loader_vit = DataLoader(train_data_vit, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим бейзлайн ResNet модель с использованием предложенных гипотез улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_model с возможностью выполнять scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "        total = len(train_loader)\n",
    "        i = 0\n",
    "        for images, labels in train_loader:\n",
    "            if i % 250 == 0:\n",
    "                print(i,\"/\", total)\n",
    "            i+=1\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f\"epoch {epoch+1}: loss: {train_loss/len(train_loader):.4f}, accuracy- {train_correct/len(train_data):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.3059, accuracy- 0.5071\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.0888, accuracy- 0.5927\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 0.9834, accuracy- 0.6306\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 4: loss: 0.8243, accuracy- 0.6901\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 5: loss: 0.7588, accuracy- 0.7152\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, None, optimizer=optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем accuracy = 0.7152, что больше, чем без улучшений. Значит, что рандомизация и scheduler действительно помогли улучшить бейзлайн."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проделаем тот же алгоритм для ViT модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_vit = vit_b_16(pretrained=True)\n",
    "model_vit.heads.head = nn.Linear(model_vit.heads.head.in_features, len(train_data.classes))\n",
    "model_vit.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_vit = optim.SGD(model_vit.parameters(), lr=0.0001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.4465, accuracy- 0.4555\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.1229, accuracy- 0.5782\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 0.9972, accuracy- 0.6272\n"
     ]
    }
   ],
   "source": [
    "train_model(model_vit, train_loader_vit, None, optimizer=optimizer_vit, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем accuracy = 0.6272, что так же больше, чем в бейзлайне. Удалось сильно улучшить уровень точности модели, оставив для обучения те же 3 эпохи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге самостоятельно имплементируем сверточную и трансформер модели машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самостоятельная имплементация трансформера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=16, emb_size=256, img_size=224):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1,emb_size))\n",
    "        num_patches = (img_size // patch_size)**2\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, num_patches +1,emb_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        cls_token = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        return x + self.pos_emb\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, emb_size=256, heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(emb_size, heads, dropout=dropout,   batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(emb_size)\n",
    "        self.norm2 = nn.LayerNorm(emb_size)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb_size, emb_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(emb_size * 4, emb_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
    "        return x\n",
    "#делаем свой трансфомер\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=3 ,  num_classes=7, emb_size=256,  depth=6):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(in_channels, patch_size, emb_size, img_size)\n",
    "        self.transformer = nn.Sequential(*[TransformerEncoder(emb_size) for _ in range(depth)])\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(emb_size),\n",
    "            nn.Linear(emb_size, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.transformer(x)\n",
    "        return self.mlp_head(x[:, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляры классов CNN и ViT моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = MyCNN(num_classes=len(train_data.classes)).to(device)\n",
    "vit_model = MyViT(num_classes=len(train_data.classes)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.0001)\n",
    "optimizer_vit = optim.SGD(vit_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct = 0, 0\n",
    "\n",
    "        total = len(train_loader)\n",
    "        i = 0\n",
    "        for images, labels in train_loader:\n",
    "            if i % 250 == 0:\n",
    "                print(i,\"/\", total)\n",
    "            i+=1\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        print(f\"epoch {epoch+1}: loss: {total_loss/len(train_loader):.4f}, accuracy- {total_correct/len(train_data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_data = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=transform)\n",
    "train_data_vit = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=vit_transform)\n",
    "\n",
    "#subset = random.sample(range(len(train_data)), int(0.2 * len(train_data)))\n",
    "#train_subset = Subset(train_data, subset) ###\n",
    "# batchsize будет 32\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "train_loader_vit = DataLoader(train_data_vit, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели и проверим полученный accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.5231, accuracy- 0.4167\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.1346, accuracy- 0.5743\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 0.8201, accuracy- 0.7003\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 4: loss: 0.5079, accuracy- 0.8222\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 5: loss: 0.2898, accuracy- 0.9040\n"
     ]
    }
   ],
   "source": [
    "train_model(cnn_model, train_loader, None, optimizer=optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось добавиться очень хорошего показателя accuracy = 0.9040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.9398, accuracy- 0.1857\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.8996, accuracy- 0.2134\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 1.8687, accuracy- 0.2370\n"
     ]
    }
   ],
   "source": [
    "train_model(vit_model, train_loader_vit, None, optimizer=optimizer_vit, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем низкий accuracy = 0.2370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примененим техники улучшения бейзлайна, использованные ранее, для самостоятельно имплементированных моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# добавляем случайности\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=train_transform)\n",
    "train_data_vit = datasets.ImageFolder(\"data/FER2013_7emotions_Uniform_Augmented_Dataset/train\", transform=vit_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "train_loader_vit = DataLoader(train_data_vit, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для CNN:\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.5607, accuracy- 0.4052\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.3927, accuracy- 0.4701\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 1.3160, accuracy- 0.4999\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 4: loss: 1.2612, accuracy- 0.5234\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 5: loss: 1.2114, accuracy- 0.5400\n"
     ]
    }
   ],
   "source": [
    "train_model(cnn_model, train_loader, None, optimizer=optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем accuracy = 0.54. Гипотезы не улучшили бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для ViT:\n",
    "optimizer = torch.optim.SGD(vit_model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 1: loss: 1.9464, accuracy- 0.1434\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 2: loss: 1.9464, accuracy- 0.1434\n",
      "0 / 1750\n",
      "250 / 1750\n",
      "500 / 1750\n",
      "750 / 1750\n",
      "1000 / 1750\n",
      "1250 / 1750\n",
      "1500 / 1750\n",
      "epoch 3: loss: 1.9464, accuracy- 0.1411\n"
     ]
    }
   ],
   "source": [
    "train_model(vit_model, train_loader_vit, None, optimizer=optimizer, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать вывод, что гипотезы не улучшили бейзлайн собственной реализации трансформерной модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
