{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был выбран датасет [leaf flower fruit annotation](https://www.kaggle.com/datasets/ar5entum/leaf-flower-fruit-annotation) (сегментация растений на фотографиях). Задача может иметь множество приложений в реальной жизни. Например, подобная система может использоваться для беспилотных автомобилей для анализа окружающей среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (78.1.0)\n",
      "Requirement already satisfied: six>=1.10 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Requirement already satisfied: pandas in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ar5entum/leaf-flower-fruit-annotation\n",
      "License(s): unknown\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d ar5entum/leaf-flower-fruit-annotation -p data7 --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.8.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pycocotools) (3.10.1)\n",
      "Requirement already satisfied: numpy in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from pycocotools) (2.2.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.8-cp313-cp313-win_amd64.whl size=82529 sha256=88790f67b49a374aee3675aaadffb5d580f39252cdc37e1a4634e68b8bd70acd\n",
      "  Stored in directory: c:\\users\\corsider\\appdata\\local\\pip\\cache\\wheels\\a3\\c8\\17\\9a271afbebc0abbc30d6d0da53284602f92208c8437b11cf32\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models_pytorch\n",
      "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting huggingface-hub>=0.24 (from segmentation_models_pytorch)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from segmentation_models_pytorch) (2.2.4)\n",
      "Requirement already satisfied: pillow>=8 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from segmentation_models_pytorch) (11.1.0)\n",
      "Collecting safetensors>=0.3.1 (from segmentation_models_pytorch)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting timm>=0.9 (from segmentation_models_pytorch)\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Requirement already satisfied: torch>=1.8 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from segmentation_models_pytorch) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from segmentation_models_pytorch) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from segmentation_models_pytorch) (4.67.1)\n",
      "Requirement already satisfied: filelock in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.24->segmentation_models_pytorch)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch>=1.8->segmentation_models_pytorch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from tqdm>=4.42.1->segmentation_models_pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2025.1.31)\n",
      "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.6/2.4 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 4.3 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Installing collected packages: safetensors, pyyaml, huggingface-hub, timm, segmentation_models_pytorch\n",
      "Successfully installed huggingface-hub-0.30.2 pyyaml-6.0.2 safetensors-0.5.3 segmentation_models_pytorch-0.5.0 timm-1.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет в формате СОСО и подготовим класс для выделения масок из изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toCOCO(Dataset):\n",
    "    def __init__(self, images_dir, annotation_file, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "        self.cat2label = {cat['id']: i+1 for i, cat in enumerate(cats)}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        img_info = self.coco.imgs[img_id]\n",
    "        path = os.path.join(self.images_dir, img_info['file_name'])\n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        h, w = img_info['height'], img_info['width']\n",
    "\n",
    "        mask = np.zeros((h,w), dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            cat = ann['category_id']\n",
    "            label = self.cat2label[cat]\n",
    "            m = self.coco.annToMask(ann)\n",
    "            mask[m == 1] = label\n",
    "\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=image, mask=mask)\n",
    "            image, mask = aug['image'], aug['mask']\n",
    "        return image, mask.long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества будем использовать F1 score (и дополнительно IoU) - стандартные метрики для задач подобного типа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: filelock in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\code\\ai_labs_2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp313-cp313-win_amd64.whl (2728.9 MB)\n",
      "   ---------------------------------------- 0.0/2.7 GB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 GB 37.7 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 0.0/2.7 GB 51.3 MB/s eta 0:00:53\n",
      "   ---------------------------------------- 0.0/2.7 GB 47.3 MB/s eta 0:00:58\n",
      "    --------------------------------------- 0.0/2.7 GB 58.0 MB/s eta 0:00:47\n",
      "    --------------------------------------- 0.1/2.7 GB 61.4 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.4 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.0 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.8 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.5 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 0.1/2.7 GB 62.2 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 0.1/2.7 GB 63.5 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.2/2.7 GB 63.8 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.2/2.7 GB 64.0 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 0.2/2.7 GB 64.2 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 0.2/2.7 GB 64.3 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 0.2/2.7 GB 64.5 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.2/2.7 GB 63.9 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 0.2/2.7 GB 64.7 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.3/2.7 GB 64.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.3/2.7 GB 67.3 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 67.1 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 66.0 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 66.0 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.3/2.7 GB 66.2 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 0.3/2.7 GB 66.6 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 65.1 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 66.4 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 65.5 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 0.4/2.7 GB 65.5 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 0.4/2.7 GB 65.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 0.4/2.7 GB 65.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 0.4/2.7 GB 65.5 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 0.5/2.7 GB 65.9 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 0.5/2.7 GB 65.6 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 65.6 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 65.1 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 64.3 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 63.9 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 63.4 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 0.5/2.7 GB 63.4 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 62.9 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 62.4 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 62.1 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.6/2.7 GB 63.4 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 0.6/2.7 GB 64.4 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.6/2.7 GB 64.3 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.6/2.7 GB 64.6 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.6/2.7 GB 64.3 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 0.7/2.7 GB 60.8 MB/s eta 0:00:35\n",
      "   --------- ------------------------------ 0.7/2.7 GB 59.6 MB/s eta 0:00:35\n",
      "   --------- ------------------------------ 0.7/2.7 GB 59.9 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 61.0 MB/s eta 0:00:34\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 60.7 MB/s eta 0:00:34\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 60.7 MB/s eta 0:00:34\n",
      "   ---------- ----------------------------- 0.7/2.7 GB 60.8 MB/s eta 0:00:33\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 61.7 MB/s eta 0:00:33\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 62.0 MB/s eta 0:00:32\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 62.7 MB/s eta 0:00:32\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 63.2 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 0.8/2.7 GB 63.5 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 0.8/2.7 GB 63.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.8/2.7 GB 63.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.9/2.7 GB 63.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.9/2.7 GB 63.1 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.9/2.7 GB 62.0 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 0.9/2.7 GB 63.0 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 0.9/2.7 GB 62.5 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 0.9/2.7 GB 65.3 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 0.9/2.7 GB 66.6 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 0.9/2.7 GB 65.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.0 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 1.0/2.7 GB 65.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 1.0/2.7 GB 65.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.0/2.7 GB 65.8 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.1/2.7 GB 65.4 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.1/2.7 GB 65.4 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 1.1/2.7 GB 64.5 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 64.9 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 64.9 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 65.0 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 1.1/2.7 GB 65.9 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 1.2/2.7 GB 66.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 67.1 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.8 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.3 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 1.2/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 1.2/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 1.3/2.7 GB 66.1 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 1.3/2.7 GB 66.5 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 1.3/2.7 GB 66.1 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 1.3/2.7 GB 65.4 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.3/2.7 GB 66.4 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.3/2.7 GB 64.6 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.3/2.7 GB 62.5 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 1.3/2.7 GB 63.8 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 1.4/2.7 GB 63.2 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 1.4/2.7 GB 63.1 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 1.4/2.7 GB 63.6 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 1.5/2.7 GB 63.2 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 1.5/2.7 GB 63.1 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 1.5/2.7 GB 63.1 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 1.5/2.7 GB 62.8 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 61.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 61.4 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 63.4 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 1.5/2.7 GB 62.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 1.6/2.7 GB 62.5 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 65.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 66.8 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 65.6 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 65.2 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.6/2.7 GB 64.3 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 1.6/2.7 GB 64.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.6 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.5 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 1.7/2.7 GB 64.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.7/2.7 GB 64.5 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.7/2.7 GB 64.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.7/2.7 GB 64.0 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 1.8/2.7 GB 65.8 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 1.8/2.7 GB 66.2 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 66.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.3 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.1 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 1.8/2.7 GB 65.5 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 1.9/2.7 GB 65.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 1.9/2.7 GB 65.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 1.9/2.7 GB 66.5 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 1.9/2.7 GB 65.1 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 1.9/2.7 GB 65.2 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 1.9/2.7 GB 67.1 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 1.9/2.7 GB 66.7 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 2.0/2.7 GB 66.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 2.0/2.7 GB 67.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 2.0/2.7 GB 67.1 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.4 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.5 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 64.0 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 2.0/2.7 GB 63.8 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 63.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 63.4 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 63.4 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 61.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 61.1 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 2.1/2.7 GB 61.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 2.1/2.7 GB 60.6 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 2.1/2.7 GB 61.4 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 2.2/2.7 GB 61.2 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 2.2/2.7 GB 61.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 2.2/2.7 GB 61.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 61.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 61.1 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 60.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 2.2/2.7 GB 60.2 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 2.3/2.7 GB 64.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 2.3/2.7 GB 64.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 2.3/2.7 GB 63.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 2.3/2.7 GB 63.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 2.3/2.7 GB 63.6 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 2.3/2.7 GB 69.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.3/2.7 GB 65.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 GB 65.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 GB 65.5 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 GB 65.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 67.4 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 64.5 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 63.1 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 63.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 2.4/2.7 GB 62.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 2.5/2.7 GB 62.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 2.5/2.7 GB 62.1 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 2.5/2.7 GB 62.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 2.5/2.7 GB 63.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 2.5/2.7 GB 63.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 2.5/2.7 GB 64.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 2.5/2.7 GB 63.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 2.5/2.7 GB 63.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 2.6/2.7 GB 63.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 2.6/2.7 GB 63.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 GB 64.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 GB 63.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.7/2.7 GB 63.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.7/2.7 GB 66.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 64.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 GB 66.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 GB 38.9 MB/s eta 0:00:00\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp313-cp313-win_amd64.whl (5.3 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-2.6.0+cu118 torchvision-0.21.0+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и создадим соответствующие даталоадеры. Число классов += 1, т.к. доп. класс будем использовать для фона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#базовые преобразования для tran и для validation данных:\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_ds = toCOCO(\n",
    "    images_dir=\"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/train\",\n",
    "    annotation_file=\"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/train.json\",\n",
    "    transform=train_transform\n",
    ")\n",
    "val_ds = toCOCO(\n",
    "    images_dir=\"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/valid\",\n",
    "    annotation_file=\"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/valid.json\",\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=0)\n",
    "num_classes = len(train_ds.cat2label) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим метод validate() для вывода статистик по обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.metrics.functional import get_stats, iou_score, f1_score\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_loss   = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_iou  = 0.0\n",
    "    total_f1   = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            #суммарный loss\n",
    "            loss = dice_loss(logits, masks) + ce_loss(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            tp, fp, fn, tn = get_stats(\n",
    "                preds, masks,\n",
    "                mode='multiclass',\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "            total_iou += iou_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "            total_f1  += f1_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "\n",
    "    n = len(loader)\n",
    "    return {'loss':total_loss/n,'iou':total_iou/n,'f1':total_f1/n}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве сверточной модели используем Unet с энкодером resnet34. В качестве трансформерной модели используем Segformer с энкодером mit_b0. Используем to(device) для использования cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=num_classes,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "model_segformer = smp.Segformer(\n",
    "    encoder_name=\"mit_b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=num_classes,\n",
    "    activation=None\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию обучения fit с удобным выводом результатов по эпохам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(imgs)\n",
    "            loss = smp.losses.DiceLoss(mode='multiclass')(logits, masks) + nn.CrossEntropyLoss()(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_res = validate(model, val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"epoch {epoch:02d} | \"\n",
    "            f\"train loss: {train_loss/len(train_loader):.4f} | \"\n",
    "            f\"val loss:   {val_res['loss']:.4f} | \"\n",
    "            f\"iou:        {val_res['iou']:.4f} | \"\n",
    "            f\"f1:         {val_res['f1']:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss: 0.7485 | val loss:   2.0331 | iou:        0.3834 | f1:         0.5543\n",
      "epoch 02 | train loss: 0.6813 | val loss:   1.7218 | iou:        0.4714 | f1:         0.6408\n",
      "epoch 03 | train loss: 0.6871 | val loss:   4.5111 | iou:        0.3692 | f1:         0.5392\n",
      "epoch 04 | train loss: 0.6138 | val loss:   1.3719 | iou:        0.6170 | f1:         0.7632\n",
      "epoch 05 | train loss: 0.4925 | val loss:   1.6242 | iou:        0.5494 | f1:         0.7091\n",
      "epoch 06 | train loss: 0.4674 | val loss:   0.8863 | iou:        0.6954 | f1:         0.8203\n",
      "epoch 07 | train loss: 0.4303 | val loss:   1.0679 | iou:        0.6925 | f1:         0.8183\n",
      "epoch 08 | train loss: 0.4010 | val loss:   1.1084 | iou:        0.6965 | f1:         0.8211\n",
      "epoch 09 | train loss: 0.3982 | val loss:   1.1562 | iou:        0.6856 | f1:         0.8135\n",
      "epoch 10 | train loss: 0.3613 | val loss:   1.1654 | iou:        0.6821 | f1:         0.8110\n",
      "epoch 11 | train loss: 0.4430 | val loss:   1.0979 | iou:        0.7168 | f1:         0.8351\n",
      "epoch 12 | train loss: 0.3366 | val loss:   1.0995 | iou:        0.6888 | f1:         0.8158\n",
      "epoch 13 | train loss: 0.3404 | val loss:   1.2579 | iou:        0.6152 | f1:         0.7618\n",
      "epoch 14 | train loss: 0.3103 | val loss:   1.1430 | iou:        0.6663 | f1:         0.7997\n",
      "epoch 15 | train loss: 0.3167 | val loss:   1.1137 | iou:        0.6922 | f1:         0.8181\n",
      "epoch 16 | train loss: 0.3043 | val loss:   1.1494 | iou:        0.7010 | f1:         0.8242\n",
      "epoch 17 | train loss: 0.2517 | val loss:   1.1491 | iou:        0.7133 | f1:         0.8327\n",
      "epoch 18 | train loss: 0.2650 | val loss:   1.1029 | iou:        0.7087 | f1:         0.8295\n",
      "epoch 19 | train loss: 0.2444 | val loss:   1.0895 | iou:        0.6892 | f1:         0.8160\n",
      "epoch 20 | train loss: 0.2427 | val loss:   1.0925 | iou:        0.7102 | f1:         0.8305\n",
      "epoch 21 | train loss: 0.2498 | val loss:   1.1107 | iou:        0.6918 | f1:         0.8178\n",
      "epoch 22 | train loss: 0.2455 | val loss:   1.1279 | iou:        0.7052 | f1:         0.8271\n",
      "epoch 23 | train loss: 0.2138 | val loss:   1.1285 | iou:        0.6897 | f1:         0.8164\n",
      "epoch 24 | train loss: 0.2543 | val loss:   1.1244 | iou:        0.6669 | f1:         0.8002\n",
      "epoch 25 | train loss: 0.2098 | val loss:   1.1629 | iou:        0.7056 | f1:         0.8274\n",
      "epoch 26 | train loss: 0.2183 | val loss:   1.2004 | iou:        0.7035 | f1:         0.8259\n",
      "epoch 27 | train loss: 0.2030 | val loss:   1.3206 | iou:        0.6855 | f1:         0.8134\n",
      "epoch 28 | train loss: 0.1806 | val loss:   1.2676 | iou:        0.6755 | f1:         0.8063\n",
      "epoch 29 | train loss: 0.1844 | val loss:   1.2832 | iou:        0.6654 | f1:         0.7991\n",
      "epoch 30 | train loss: 0.1667 | val loss:   1.2570 | iou:        0.6752 | f1:         0.8061\n"
     ]
    }
   ],
   "source": [
    "fit(model_unet, train_loader, val_loader, epochs=30, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем очень хорошие показатели f1 - 0.8061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss: 1.6040 | val loss:   1.0779 | iou:        0.6446 | f1:         0.7839\n",
      "epoch 02 | train loss: 1.0121 | val loss:   1.3077 | iou:        0.5892 | f1:         0.7415\n",
      "epoch 03 | train loss: 0.7509 | val loss:   0.9538 | iou:        0.7103 | f1:         0.8306\n",
      "epoch 04 | train loss: 0.5791 | val loss:   1.0355 | iou:        0.6731 | f1:         0.8046\n",
      "epoch 05 | train loss: 0.5196 | val loss:   0.9659 | iou:        0.7088 | f1:         0.8296\n",
      "epoch 06 | train loss: 0.4624 | val loss:   1.0016 | iou:        0.6773 | f1:         0.8076\n",
      "epoch 07 | train loss: 0.4369 | val loss:   0.9907 | iou:        0.7161 | f1:         0.8346\n",
      "epoch 08 | train loss: 0.3858 | val loss:   1.1799 | iou:        0.6593 | f1:         0.7947\n",
      "epoch 09 | train loss: 0.3459 | val loss:   1.0917 | iou:        0.6895 | f1:         0.8162\n",
      "epoch 10 | train loss: 0.3552 | val loss:   1.0182 | iou:        0.7040 | f1:         0.8263\n",
      "epoch 11 | train loss: 0.3333 | val loss:   0.9461 | iou:        0.6932 | f1:         0.8188\n",
      "epoch 12 | train loss: 0.2879 | val loss:   0.9151 | iou:        0.6994 | f1:         0.8231\n",
      "epoch 13 | train loss: 0.2821 | val loss:   0.9186 | iou:        0.7045 | f1:         0.8266\n",
      "epoch 14 | train loss: 0.2824 | val loss:   0.8974 | iou:        0.6920 | f1:         0.8180\n",
      "epoch 15 | train loss: 0.2532 | val loss:   0.9101 | iou:        0.6997 | f1:         0.8233\n",
      "epoch 16 | train loss: 0.2724 | val loss:   1.1030 | iou:        0.6712 | f1:         0.8033\n",
      "epoch 17 | train loss: 0.2521 | val loss:   1.1452 | iou:        0.6763 | f1:         0.8069\n",
      "epoch 18 | train loss: 0.2570 | val loss:   1.0631 | iou:        0.6813 | f1:         0.8104\n",
      "epoch 19 | train loss: 0.2368 | val loss:   1.0396 | iou:        0.6567 | f1:         0.7927\n",
      "epoch 20 | train loss: 0.2642 | val loss:   1.1584 | iou:        0.6898 | f1:         0.8164\n",
      "epoch 21 | train loss: 0.2284 | val loss:   1.1552 | iou:        0.6951 | f1:         0.8201\n",
      "epoch 22 | train loss: 0.2270 | val loss:   1.1483 | iou:        0.6587 | f1:         0.7942\n",
      "epoch 23 | train loss: 0.2232 | val loss:   0.9439 | iou:        0.7175 | f1:         0.8355\n",
      "epoch 24 | train loss: 0.2318 | val loss:   1.0364 | iou:        0.6616 | f1:         0.7964\n",
      "epoch 25 | train loss: 0.2225 | val loss:   0.9230 | iou:        0.7071 | f1:         0.8284\n",
      "epoch 26 | train loss: 0.2034 | val loss:   0.9926 | iou:        0.7187 | f1:         0.8364\n",
      "epoch 27 | train loss: 0.1877 | val loss:   1.0538 | iou:        0.6988 | f1:         0.8227\n",
      "epoch 28 | train loss: 0.1976 | val loss:   0.9962 | iou:        0.7128 | f1:         0.8323\n",
      "epoch 29 | train loss: 0.1768 | val loss:   1.0201 | iou:        0.6962 | f1:         0.8209\n",
      "epoch 30 | train loss: 0.1720 | val loss:   1.0804 | iou:        0.6992 | f1:         0.8230\n"
     ]
    }
   ],
   "source": [
    "fit(model_segformer, train_loader, val_loader, epochs=30, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем f1=0.823 - что являетя очень хорошим результатом (превосходящим результат cnn модели)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотезы\n",
    "\n",
    "Добавим более агрессивные аугментации (цветовые искажения, повороты), поменяем оптимизатор на AdamW и добавим Scheduler.\n",
    "\n",
    "Размер батча поставим 16, уменьшим learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "improv_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(p=0.5),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_ds.transform = improv_transform\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "model_unet_improv = smp.Unet(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=num_classes,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "#оптимизатор и scheduler\n",
    "optimizer = optim.AdamW(model_unet_improv.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()\n",
    "\n",
    "#новая функция обучения\n",
    "def fit_improved(model, train_loader, val_loader, epochs):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = dice_loss(logits, masks) + ce_loss(logits, masks)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        scheduler.step() # шаг scheduler-а\n",
    "        val_res = validate(model, val_loader)\n",
    "        print(\n",
    "            f\"epoch {epoch:02d} | \"\n",
    "            f\"train loss: {train_loss/len(train_loader):.4f} | \"\n",
    "            f\"val loss:   {val_res['loss']:.4f} | \"\n",
    "            f\"iou:        {val_res['iou']:.4f} | \"\n",
    "            f\"f1:         {val_res['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим бейзлайн cnn модель с использованием предложенных гипотез улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss: 2.3907 | val loss:   2.5415 | iou:        0.1152 | f1:         0.2066\n",
      "epoch 02 | train loss: 2.0892 | val loss:   2.0869 | iou:        0.2111 | f1:         0.3486\n",
      "epoch 03 | train loss: 1.8888 | val loss:   1.9070 | iou:        0.3959 | f1:         0.5672\n",
      "epoch 04 | train loss: 1.7550 | val loss:   1.7736 | iou:        0.5483 | f1:         0.7082\n",
      "epoch 05 | train loss: 1.6937 | val loss:   1.6789 | iou:        0.6249 | f1:         0.7691\n",
      "epoch 06 | train loss: 1.5642 | val loss:   1.6345 | iou:        0.6525 | f1:         0.7897\n",
      "epoch 07 | train loss: 1.5402 | val loss:   1.6080 | iou:        0.6588 | f1:         0.7943\n",
      "epoch 08 | train loss: 1.4956 | val loss:   1.5944 | iou:        0.6531 | f1:         0.7901\n",
      "epoch 09 | train loss: 1.4618 | val loss:   1.5831 | iou:        0.6555 | f1:         0.7919\n",
      "epoch 10 | train loss: 1.4756 | val loss:   1.5884 | iou:        0.6445 | f1:         0.7838\n",
      "epoch 11 | train loss: 1.4651 | val loss:   1.5855 | iou:        0.6449 | f1:         0.7841\n",
      "epoch 12 | train loss: 1.4677 | val loss:   1.5805 | iou:        0.6446 | f1:         0.7839\n",
      "epoch 13 | train loss: 1.4405 | val loss:   1.5774 | iou:        0.6458 | f1:         0.7848\n",
      "epoch 14 | train loss: 1.4197 | val loss:   1.5577 | iou:        0.6534 | f1:         0.7903\n",
      "epoch 15 | train loss: 1.3962 | val loss:   1.5415 | iou:        0.6523 | f1:         0.7896\n",
      "epoch 16 | train loss: 1.3801 | val loss:   1.5053 | iou:        0.6613 | f1:         0.7961\n",
      "epoch 17 | train loss: 1.3350 | val loss:   1.4675 | iou:        0.6704 | f1:         0.8027\n",
      "epoch 18 | train loss: 1.2605 | val loss:   1.4561 | iou:        0.6648 | f1:         0.7987\n",
      "epoch 19 | train loss: 1.2595 | val loss:   1.4397 | iou:        0.6604 | f1:         0.7955\n",
      "epoch 20 | train loss: 1.1791 | val loss:   1.3966 | iou:        0.6704 | f1:         0.8027\n",
      "epoch 21 | train loss: 1.1818 | val loss:   1.3841 | iou:        0.6689 | f1:         0.8016\n",
      "epoch 22 | train loss: 1.1297 | val loss:   1.3456 | iou:        0.6860 | f1:         0.8138\n",
      "epoch 23 | train loss: 1.0843 | val loss:   1.3649 | iou:        0.6740 | f1:         0.8052\n",
      "epoch 24 | train loss: 1.0366 | val loss:   1.3288 | iou:        0.6789 | f1:         0.8088\n",
      "epoch 25 | train loss: 0.9691 | val loss:   1.2974 | iou:        0.6980 | f1:         0.8221\n",
      "epoch 26 | train loss: 0.9434 | val loss:   1.2553 | iou:        0.7120 | f1:         0.8317\n",
      "epoch 27 | train loss: 0.9513 | val loss:   1.2584 | iou:        0.7091 | f1:         0.8298\n",
      "epoch 28 | train loss: 0.9617 | val loss:   1.2558 | iou:        0.7058 | f1:         0.8275\n",
      "epoch 29 | train loss: 0.9255 | val loss:   1.2441 | iou:        0.7091 | f1:         0.8298\n",
      "epoch 30 | train loss: 0.9102 | val loss:   1.2299 | iou:        0.7132 | f1:         0.8326\n"
     ]
    }
   ],
   "source": [
    "fit_improved(model_unet_improv, train_loader, val_loader, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гипотезы помогли и привели к улучшению и без того хорошего результата до f1=0.8326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим для трансформерной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from torch import optim, nn\n",
    "\n",
    "model_segformer_improv = smp.Segformer(\n",
    "    encoder_name=\"mit_b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=num_classes,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model_segformer_improv.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()\n",
    "\n",
    "def fit_improved_trans(model, train_loader, val_loader, epochs):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = dice_loss(logits, masks) + ce_loss(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        val_res = validate(model, val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"epoch {epoch:02d} | \"\n",
    "            f\"train loss: {train_loss/len(train_loader):.4f} | \"\n",
    "            f\"val loss:   {val_res['loss']:.4f} | \"\n",
    "            f\"ioo:        {val_res['iou']:.4f} | \"\n",
    "            f\"f1:         {val_res['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss: 1.8881 | val loss:   1.3488 | ioo:        0.5234 | f1:         0.6871\n",
      "epoch 02 | train loss: 1.2422 | val loss:   1.1255 | ioo:        0.6181 | f1:         0.7639\n",
      "epoch 03 | train loss: 0.9305 | val loss:   1.0054 | ioo:        0.6676 | f1:         0.8007\n",
      "epoch 04 | train loss: 0.8034 | val loss:   1.0521 | ioo:        0.6572 | f1:         0.7931\n",
      "epoch 05 | train loss: 0.7378 | val loss:   1.0719 | ioo:        0.6494 | f1:         0.7875\n",
      "epoch 06 | train loss: 0.6757 | val loss:   1.0029 | ioo:        0.6686 | f1:         0.8014\n",
      "epoch 07 | train loss: 0.6503 | val loss:   1.0071 | ioo:        0.6574 | f1:         0.7933\n",
      "epoch 08 | train loss: 0.6127 | val loss:   1.0301 | ioo:        0.6517 | f1:         0.7891\n",
      "epoch 09 | train loss: 0.6334 | val loss:   1.0155 | ioo:        0.6590 | f1:         0.7945\n",
      "epoch 10 | train loss: 0.6498 | val loss:   1.0001 | ioo:        0.6615 | f1:         0.7963\n",
      "epoch 11 | train loss: 0.5962 | val loss:   0.9990 | ioo:        0.6626 | f1:         0.7970\n",
      "epoch 12 | train loss: 0.6260 | val loss:   1.0085 | ioo:        0.6613 | f1:         0.7961\n",
      "epoch 13 | train loss: 0.6237 | val loss:   0.9986 | ioo:        0.6673 | f1:         0.8005\n",
      "epoch 14 | train loss: 0.6112 | val loss:   0.9840 | ioo:        0.6756 | f1:         0.8064\n",
      "epoch 15 | train loss: 0.5770 | val loss:   0.9773 | ioo:        0.6766 | f1:         0.8071\n",
      "epoch 16 | train loss: 0.5709 | val loss:   0.9818 | ioo:        0.6787 | f1:         0.8086\n",
      "epoch 17 | train loss: 0.5473 | val loss:   0.9972 | ioo:        0.6751 | f1:         0.8060\n",
      "epoch 18 | train loss: 0.5220 | val loss:   1.0834 | ioo:        0.6673 | f1:         0.8005\n",
      "epoch 19 | train loss: 0.5097 | val loss:   1.0326 | ioo:        0.6821 | f1:         0.8110\n",
      "epoch 20 | train loss: 0.4785 | val loss:   0.9928 | ioo:        0.6941 | f1:         0.8195\n",
      "epoch 21 | train loss: 0.4556 | val loss:   1.0576 | ioo:        0.6724 | f1:         0.8041\n",
      "epoch 22 | train loss: 0.4252 | val loss:   1.0499 | ioo:        0.6980 | f1:         0.8222\n",
      "epoch 23 | train loss: 0.4035 | val loss:   1.0549 | ioo:        0.6986 | f1:         0.8226\n",
      "epoch 24 | train loss: 0.4082 | val loss:   1.0557 | ioo:        0.6903 | f1:         0.8168\n",
      "epoch 25 | train loss: 0.4330 | val loss:   1.0885 | ioo:        0.6824 | f1:         0.8112\n",
      "epoch 26 | train loss: 0.4131 | val loss:   1.0757 | ioo:        0.6836 | f1:         0.8121\n",
      "epoch 27 | train loss: 0.3740 | val loss:   1.0790 | ioo:        0.6979 | f1:         0.8221\n",
      "epoch 28 | train loss: 0.3668 | val loss:   1.0783 | ioo:        0.6957 | f1:         0.8206\n",
      "epoch 29 | train loss: 0.3931 | val loss:   1.0749 | ioo:        0.6925 | f1:         0.8183\n",
      "epoch 30 | train loss: 0.3701 | val loss:   1.0650 | ioo:        0.6934 | f1:         0.8189\n"
     ]
    }
   ],
   "source": [
    "fit_improved_trans(model_segformer_improv, train_loader, val_loader, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем f1=0.8189, значит гипотезы не улучшили бейзлайн трансформерной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге самостоятельно имплементируем сверточную и трансформер модели машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MyCnn(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.down1 = DoubleConv(3, 64)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.down2 = DoubleConv(64, 128)\n",
    "        self.down3 = DoubleConv(128, 256)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.upconv3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.upconv2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.upconv1 = DoubleConv(128, 64)\n",
    "        self.final = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(self.pool(d1))\n",
    "        d3 = self.down3(self.pool(d2))\n",
    "        bn = self.bottleneck(self.pool(d3))\n",
    "        u3 = self.upconv3(torch.cat([self.up3(bn), d3], dim=1))\n",
    "        u2 = self.upconv2(torch.cat([self.up2(u3), d2], dim=1))\n",
    "        u1 = self.upconv1(torch.cat([self.up1(u2), d1], dim=1))\n",
    "        return self.final(u1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самостоятельная имплементация трансформера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size=224, patch_size=32, in_ch=3,\n",
    "                 embed_dim=128, num_heads=4, depth=2,\n",
    "                 num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        assert img_size % patch_size == 0\n",
    "        num_patches = (img_size // patch_size) **2\n",
    "        self.patch_embed = nn.Conv2d(in_ch, embed_dim,kernel_size=patch_size, stride=patch_size)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embed_dim*2,\n",
    "            dropout=0.1,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embed_dim, embed_dim,kernel_size=patch_size,stride=patch_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(embed_dim, embed_dim//2,3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(embed_dim//2, num_classes, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)+self.pos_embed\n",
    "        x = x.permute(1,0,2)\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        x = x.transpose(1, 2).view(B, C,H,W)\n",
    "        return self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидатор для своих реализаций моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.metrics.functional import get_stats, iou_score, f1_score\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_loss   = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = total_iou = total_f1 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = dice_loss(logits, masks) + ce_loss(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            tp, fp, fn, tn = get_stats(preds, masks,mode='multiclass',num_classes=num_classes)\n",
    "            total_iou += iou_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "            total_f1  += f1_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "\n",
    "    n = len(loader)\n",
    "    return {'loss': total_loss/n,'iou':total_iou/n,'f1':total_f1/n}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция обучения для кастомных моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def fit_cust(model, train_loader, val_loader, epochs, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(imgs)\n",
    "            loss = smp.losses.DiceLoss(mode='multiclass')(logits, masks) + \\\n",
    "                   nn.CrossEntropyLoss()(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_res = validate(model, val_loader)\n",
    "        print(f\"epoch {epoch:02d}| \"\n",
    "              f\"taining loss: {train_loss/len(train_loader):.4f}  | \"\n",
    "              f\"val loss: {val_res['loss']:.4f} | \"\n",
    "              f\"iou: {val_res['iou']:.4f} | \"\n",
    "              f\"f1: {val_res['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_my = MyCnn(num_classes).to(device) # экземпляр кастомной cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01| taining loss: 2.0628  | val loss: 1.8179 | iou: 0.5320 | f1: 0.6945\n",
      "epoch 02| taining loss: 1.7665  | val loss: 1.9267 | iou: 0.4437 | f1: 0.6147\n",
      "epoch 03| taining loss: 1.7211  | val loss: 1.7088 | iou: 0.5317 | f1: 0.6942\n",
      "epoch 04| taining loss: 1.6611  | val loss: 1.6852 | iou: 0.4909 | f1: 0.6586\n",
      "epoch 05| taining loss: 1.6423  | val loss: 1.6912 | iou: 0.4683 | f1: 0.6378\n",
      "epoch 06| taining loss: 1.6417  | val loss: 1.6640 | iou: 0.4591 | f1: 0.6293\n",
      "epoch 07| taining loss: 1.5881  | val loss: 1.6285 | iou: 0.4985 | f1: 0.6654\n",
      "epoch 08| taining loss: 1.5915  | val loss: 1.6381 | iou: 0.4981 | f1: 0.6649\n",
      "epoch 09| taining loss: 1.5628  | val loss: 1.6453 | iou: 0.4622 | f1: 0.6322\n",
      "epoch 10| taining loss: 1.5760  | val loss: 1.6208 | iou: 0.4812 | f1: 0.6497\n",
      "epoch 11| taining loss: 1.5284  | val loss: 1.5706 | iou: 0.5264 | f1: 0.6897\n",
      "epoch 12| taining loss: 1.5851  | val loss: 1.7538 | iou: 0.4138 | f1: 0.5854\n",
      "epoch 13| taining loss: 1.5942  | val loss: 1.5687 | iou: 0.5618 | f1: 0.7194\n",
      "epoch 14| taining loss: 1.5353  | val loss: 1.5566 | iou: 0.5269 | f1: 0.6901\n",
      "epoch 15| taining loss: 1.5376  | val loss: 1.5661 | iou: 0.5073 | f1: 0.6731\n",
      "epoch 16| taining loss: 1.5734  | val loss: 1.6332 | iou: 0.4800 | f1: 0.6487\n",
      "epoch 17| taining loss: 1.5276  | val loss: 1.6167 | iou: 0.5014 | f1: 0.6679\n",
      "epoch 18| taining loss: 1.5295  | val loss: 1.6233 | iou: 0.4896 | f1: 0.6573\n",
      "epoch 19| taining loss: 1.4830  | val loss: 1.5897 | iou: 0.4506 | f1: 0.6213\n",
      "epoch 20| taining loss: 1.5615  | val loss: 1.5620 | iou: 0.4643 | f1: 0.6342\n",
      "epoch 21| taining loss: 1.5416  | val loss: 1.6061 | iou: 0.4791 | f1: 0.6479\n",
      "epoch 22| taining loss: 1.5416  | val loss: 1.6057 | iou: 0.4816 | f1: 0.6501\n",
      "epoch 23| taining loss: 1.5621  | val loss: 1.5628 | iou: 0.5152 | f1: 0.6800\n",
      "epoch 24| taining loss: 1.4859  | val loss: 1.6201 | iou: 0.4550 | f1: 0.6254\n",
      "epoch 25| taining loss: 1.4487  | val loss: 1.6083 | iou: 0.4603 | f1: 0.6304\n",
      "epoch 26| taining loss: 1.4421  | val loss: 1.4870 | iou: 0.5091 | f1: 0.6747\n",
      "epoch 27| taining loss: 1.5064  | val loss: 1.5389 | iou: 0.4884 | f1: 0.6563\n",
      "epoch 28| taining loss: 1.4995  | val loss: 1.4767 | iou: 0.5317 | f1: 0.6942\n",
      "epoch 29| taining loss: 1.4835  | val loss: 1.5226 | iou: 0.4891 | f1: 0.6569\n",
      "epoch 30| taining loss: 1.4854  | val loss: 1.5459 | iou: 0.4777 | f1: 0.6465\n"
     ]
    }
   ],
   "source": [
    "fit_cust(model_cnn_my, train_loader, val_loader, epochs=30, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем более низкий результат - f1=0.6465, это ниже, чем у библиотечной модели. Проведем те же действия для трансформерной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI_labs_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_transf = MyTransformer(\n",
    "    img_size=224, patch_size=32,\n",
    "    in_ch=3, embed_dim=128,\n",
    "    num_heads=4, depth=2,\n",
    "    num_classes=num_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим трансформер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01| taining loss: 2.0618  | val loss: 1.7457 | iou: 0.5294 | f1: 0.6923\n",
      "epoch 02| taining loss: 1.7684  | val loss: 1.7108 | iou: 0.5320 | f1: 0.6945\n",
      "epoch 03| taining loss: 1.6742  | val loss: 1.7155 | iou: 0.5320 | f1: 0.6945\n",
      "epoch 04| taining loss: 1.6854  | val loss: 1.7120 | iou: 0.4254 | f1: 0.5969\n",
      "epoch 05| taining loss: 1.6812  | val loss: 1.6333 | iou: 0.4508 | f1: 0.6215\n",
      "epoch 06| taining loss: 1.6517  | val loss: 1.7101 | iou: 0.4544 | f1: 0.6248\n",
      "epoch 07| taining loss: 1.5941  | val loss: 1.7215 | iou: 0.4551 | f1: 0.6255\n",
      "epoch 08| taining loss: 1.5703  | val loss: 1.6425 | iou: 0.5034 | f1: 0.6697\n",
      "epoch 09| taining loss: 1.5482  | val loss: 1.5803 | iou: 0.5454 | f1: 0.7058\n",
      "epoch 10| taining loss: 1.5940  | val loss: 1.7372 | iou: 0.4530 | f1: 0.6235\n",
      "epoch 11| taining loss: 1.4506  | val loss: 1.6632 | iou: 0.3975 | f1: 0.5689\n",
      "epoch 12| taining loss: 1.5116  | val loss: 1.6712 | iou: 0.3864 | f1: 0.5574\n",
      "epoch 13| taining loss: 1.4403  | val loss: 1.6898 | iou: 0.3649 | f1: 0.5347\n",
      "epoch 14| taining loss: 1.4831  | val loss: 1.6443 | iou: 0.4304 | f1: 0.6017\n",
      "epoch 15| taining loss: 1.5097  | val loss: 1.5751 | iou: 0.4048 | f1: 0.5763\n",
      "epoch 16| taining loss: 1.5453  | val loss: 1.6317 | iou: 0.3807 | f1: 0.5515\n",
      "epoch 17| taining loss: 1.5042  | val loss: 1.6909 | iou: 0.4503 | f1: 0.6210\n",
      "epoch 18| taining loss: 1.4919  | val loss: 1.6741 | iou: 0.4034 | f1: 0.5748\n",
      "epoch 19| taining loss: 1.4491  | val loss: 1.7729 | iou: 0.4123 | f1: 0.5839\n",
      "epoch 20| taining loss: 1.4882  | val loss: 1.7182 | iou: 0.4300 | f1: 0.6014\n",
      "epoch 21| taining loss: 1.3887  | val loss: 1.7082 | iou: 0.3812 | f1: 0.5520\n",
      "epoch 22| taining loss: 1.4110  | val loss: 1.6690 | iou: 0.4638 | f1: 0.6337\n",
      "epoch 23| taining loss: 1.4169  | val loss: 1.7707 | iou: 0.3977 | f1: 0.5691\n",
      "epoch 24| taining loss: 1.3671  | val loss: 1.8651 | iou: 0.3610 | f1: 0.5305\n",
      "epoch 25| taining loss: 1.3859  | val loss: 1.8157 | iou: 0.4105 | f1: 0.5821\n",
      "epoch 26| taining loss: 1.4892  | val loss: 1.7128 | iou: 0.4380 | f1: 0.6091\n",
      "epoch 27| taining loss: 1.5090  | val loss: 1.7317 | iou: 0.3993 | f1: 0.5707\n",
      "epoch 28| taining loss: 1.4397  | val loss: 1.6859 | iou: 0.4088 | f1: 0.5804\n",
      "epoch 29| taining loss: 1.4935  | val loss: 1.7933 | iou: 0.4303 | f1: 0.6017\n",
      "epoch 30| taining loss: 1.4153  | val loss: 1.6518 | iou: 0.4329 | f1: 0.6042\n"
     ]
    }
   ],
   "source": [
    "fit_cust(model_transf, train_loader, val_loader, epochs=30, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось добавиться показателя f1=0.6042. Теперь перейдем к применениям техник улучшения бейзлайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_s = optim.AdamW(model_cnn_my.parameters(), lr=1e-4)\n",
    "scheduler_s = optim.lr_scheduler.CosineAnnealingLR(optimizer_s, T_max=10)\n",
    "optimizer_t = optim.AdamW(model_transf.parameters(), lr=1e-4)\n",
    "scheduler_t = optim.lr_scheduler.CosineAnnealingLR(optimizer_t, T_max=10)\n",
    "\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()\n",
    "def fit_cust_imrpv(model, optimizer, scheduler, train_loader, val_loader, epochs=30):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tl = 0.0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(imgs)\n",
    "            loss = dice_loss(logits, masks) + ce_loss(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tl += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        vr = validate(model, val_loader)\n",
    "        print(f\"epoch {epoch:02d}| \"\n",
    "              f\"tr loss: {tl/len(train_loader):.4f}  | \"\n",
    "              f\"val loss: {vr['loss']:.4f} | \"\n",
    "              f\"iou: {vr['iou']:.4f} | \"\n",
    "              f\"f1: {vr['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим CNN модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01| tr loss: 1.4548  | val loss: 1.5101 | iou: 0.4953 | f1: 0.6624\n",
      "epoch 02| tr loss: 1.4346  | val loss: 1.5052 | iou: 0.4936 | f1: 0.6610\n",
      "epoch 03| tr loss: 1.4826  | val loss: 1.5004 | iou: 0.4955 | f1: 0.6627\n",
      "epoch 04| tr loss: 1.4041  | val loss: 1.4565 | iou: 0.5158 | f1: 0.6806\n",
      "epoch 05| tr loss: 1.3488  | val loss: 1.4569 | iou: 0.5127 | f1: 0.6779\n",
      "epoch 06| tr loss: 1.4004  | val loss: 1.4462 | iou: 0.5158 | f1: 0.6805\n",
      "epoch 07| tr loss: 1.3679  | val loss: 1.4690 | iou: 0.5048 | f1: 0.6709\n",
      "epoch 08| tr loss: 1.3713  | val loss: 1.4474 | iou: 0.5142 | f1: 0.6792\n",
      "epoch 09| tr loss: 1.4190  | val loss: 1.4502 | iou: 0.5127 | f1: 0.6778\n",
      "epoch 10| tr loss: 1.3776  | val loss: 1.4489 | iou: 0.5134 | f1: 0.6784\n",
      "epoch 11| tr loss: 1.3883  | val loss: 1.4489 | iou: 0.5134 | f1: 0.6784\n",
      "epoch 12| tr loss: 1.3809  | val loss: 1.4499 | iou: 0.5128 | f1: 0.6780\n",
      "epoch 13| tr loss: 1.3508  | val loss: 1.4490 | iou: 0.5133 | f1: 0.6784\n",
      "epoch 14| tr loss: 1.3883  | val loss: 1.4353 | iou: 0.5206 | f1: 0.6847\n",
      "epoch 15| tr loss: 1.4086  | val loss: 1.4597 | iou: 0.5086 | f1: 0.6743\n",
      "epoch 16| tr loss: 1.3890  | val loss: 1.4333 | iou: 0.5205 | f1: 0.6846\n",
      "epoch 17| tr loss: 1.3695  | val loss: 1.4598 | iou: 0.5036 | f1: 0.6699\n",
      "epoch 18| tr loss: 1.3704  | val loss: 1.4530 | iou: 0.5066 | f1: 0.6725\n",
      "epoch 19| tr loss: 1.3649  | val loss: 1.4184 | iou: 0.5212 | f1: 0.6852\n",
      "epoch 20| tr loss: 1.3276  | val loss: 1.4214 | iou: 0.5182 | f1: 0.6826\n",
      "epoch 21| tr loss: 1.3721  | val loss: 1.4206 | iou: 0.5178 | f1: 0.6823\n",
      "epoch 22| tr loss: 1.3454  | val loss: 1.3814 | iou: 0.5301 | f1: 0.6929\n",
      "epoch 23| tr loss: 1.3424  | val loss: 1.4256 | iou: 0.5084 | f1: 0.6741\n",
      "epoch 24| tr loss: 1.3333  | val loss: 1.4180 | iou: 0.5089 | f1: 0.6745\n",
      "epoch 25| tr loss: 1.4141  | val loss: 1.3885 | iou: 0.5207 | f1: 0.6848\n",
      "epoch 26| tr loss: 1.3996  | val loss: 1.4067 | iou: 0.5144 | f1: 0.6794\n",
      "epoch 27| tr loss: 1.3665  | val loss: 1.4062 | iou: 0.5148 | f1: 0.6797\n",
      "epoch 28| tr loss: 1.3508  | val loss: 1.3824 | iou: 0.5250 | f1: 0.6885\n",
      "epoch 29| tr loss: 1.3943  | val loss: 1.3944 | iou: 0.5200 | f1: 0.6842\n",
      "epoch 30| tr loss: 1.3412  | val loss: 1.3951 | iou: 0.5197 | f1: 0.6840\n"
     ]
    }
   ],
   "source": [
    "fit_cust_imrpv(model_cnn_my, optimizer_s, scheduler_s, train_loader, val_loader, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем f1=0.6840, что немного выше бейзлайн значений. Значит, техники улучшения действительно улучшили бейзлайн кастомной модели. Теперь переейдем к обучению трансформер-модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01| tr loss: 1.3957  | val loss: 1.6563 | iou: 0.4427 | f1: 0.6137\n",
      "epoch 02| tr loss: 1.3283  | val loss: 1.6944 | iou: 0.4507 | f1: 0.6214\n",
      "epoch 03| tr loss: 1.3418  | val loss: 1.7260 | iou: 0.4318 | f1: 0.6031\n",
      "epoch 04| tr loss: 1.3740  | val loss: 1.7304 | iou: 0.4195 | f1: 0.5911\n",
      "epoch 05| tr loss: 1.3369  | val loss: 1.7340 | iou: 0.4189 | f1: 0.5905\n",
      "epoch 06| tr loss: 1.3631  | val loss: 1.7433 | iou: 0.4123 | f1: 0.5838\n",
      "epoch 07| tr loss: 1.3035  | val loss: 1.7373 | iou: 0.4126 | f1: 0.5842\n",
      "epoch 08| tr loss: 1.3074  | val loss: 1.7298 | iou: 0.4113 | f1: 0.5829\n",
      "epoch 09| tr loss: 1.3028  | val loss: 1.7272 | iou: 0.4112 | f1: 0.5828\n",
      "epoch 10| tr loss: 1.3571  | val loss: 1.7273 | iou: 0.4111 | f1: 0.5827\n",
      "epoch 11| tr loss: 1.3928  | val loss: 1.7273 | iou: 0.4111 | f1: 0.5827\n",
      "epoch 12| tr loss: 1.3419  | val loss: 1.7274 | iou: 0.4113 | f1: 0.5829\n",
      "epoch 13| tr loss: 1.2620  | val loss: 1.7248 | iou: 0.4119 | f1: 0.5835\n",
      "epoch 14| tr loss: 1.3306  | val loss: 1.7225 | iou: 0.4127 | f1: 0.5843\n",
      "epoch 15| tr loss: 1.2871  | val loss: 1.7274 | iou: 0.4094 | f1: 0.5809\n",
      "epoch 16| tr loss: 1.3158  | val loss: 1.7266 | iou: 0.4102 | f1: 0.5818\n",
      "epoch 17| tr loss: 1.2762  | val loss: 1.7292 | iou: 0.4168 | f1: 0.5884\n",
      "epoch 18| tr loss: 1.3029  | val loss: 1.7304 | iou: 0.4180 | f1: 0.5896\n",
      "epoch 19| tr loss: 1.3028  | val loss: 1.7444 | iou: 0.4194 | f1: 0.5910\n",
      "epoch 20| tr loss: 1.2733  | val loss: 1.7643 | iou: 0.4179 | f1: 0.5895\n",
      "epoch 21| tr loss: 1.3661  | val loss: 1.7585 | iou: 0.4130 | f1: 0.5846\n",
      "epoch 22| tr loss: 1.3262  | val loss: 1.7579 | iou: 0.4123 | f1: 0.5839\n",
      "epoch 23| tr loss: 1.2840  | val loss: 1.7369 | iou: 0.4110 | f1: 0.5826\n",
      "epoch 24| tr loss: 1.3128  | val loss: 1.7299 | iou: 0.4042 | f1: 0.5757\n",
      "epoch 25| tr loss: 1.2619  | val loss: 1.7243 | iou: 0.4068 | f1: 0.5783\n",
      "epoch 26| tr loss: 1.3228  | val loss: 1.7097 | iou: 0.4176 | f1: 0.5892\n",
      "epoch 27| tr loss: 1.3413  | val loss: 1.7074 | iou: 0.4198 | f1: 0.5914\n",
      "epoch 28| tr loss: 1.3210  | val loss: 1.7070 | iou: 0.4173 | f1: 0.5889\n",
      "epoch 29| tr loss: 1.2540  | val loss: 1.7084 | iou: 0.4157 | f1: 0.5873\n",
      "epoch 30| tr loss: 1.2850  | val loss: 1.7082 | iou: 0.4151 | f1: 0.5867\n"
     ]
    }
   ],
   "source": [
    "fit_cust_imrpv(model_transf, optimizer_t, scheduler_t, train_loader, val_loader, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем f1=0.5867, что значит, что гипотезы не улучшили бейзлайн кастомной трансформерной модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
